{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474188ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_231398/912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import habana_frameworks.torch.core as htcore\n",
    "import numpy as np\n",
    "import opendatasets as od\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from PIL import Image, ImageChops\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from unet import UNET\n",
    "from utils import get_data, load_hpu_library, set_env_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_env_params(run_lazy_mode=True, hpus_per_node=1)\n",
    "load_hpu_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a562480",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "png = \".png\"\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, cxr_dir, mask_dir, transform=None):\n",
    "        self.cxr_images = glob(os.path.join(cxr_dir, \"*{}\".format(png)))\n",
    "        self.mask_images = glob(os.path.join(mask_dir, \"*{}\".format(png)))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cxr_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cxr_png_path = Path(self.cxr_images[idx])\n",
    "        mask_png_path = Path(self.mask_images[idx])\n",
    "        img = np.array(Image.open(cxr_png_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_png_path).convert(\"L\"), dtype=np.float32)\n",
    "        mask[mask == 255.0] = 1.0\n",
    "\n",
    "        if self.transform:\n",
    "            augs = self.transform(image=img, mask=mask)\n",
    "            img = augs[\"image\"]\n",
    "            mask = augs[\"mask\"]\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf078b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=dim, width=dim, always_apply=True),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_dir = \"data/proc_seg/cxr_pngs/\"\n",
    "mask_dir = \"data/proc_seg/mask_pngs/\"\n",
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(cxr_dir=cxr_dir, mask_dir=mask_dir, transform=transforms)\n",
    "train_samples = int(len(dataset) * 0.8)\n",
    "train_data, val_data = random_split(\n",
    "    dataset, [train_samples, len(dataset) - train_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f379ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=bs, shuffle=True, pin_memory=True, num_workers=os.cpu_count()\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data, batch_size=bs, shuffle=False, pin_memory=True, num_workers=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET(in_channels=3, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c81e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"hpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb098446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute the params from filters first (KCRS) to filters last(RSCK) or vice versa.\n",
    "# and permute from RSCK to KCRS is used for checkpoint saving\n",
    "def permute_params(model, to_filters_last, lazy_mode):\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.ndim == 4:\n",
    "                if to_filters_last:\n",
    "                    param.data = param.data.permute((2, 3, 1, 0))\n",
    "                else:\n",
    "                    param.data = param.data.permute(\n",
    "                        (3, 2, 0, 1)\n",
    "                    )  # permute RSCK to KCRS\n",
    "\n",
    "    if lazy_mode:\n",
    "        import habana_frameworks.torch.core as htcore\n",
    "\n",
    "        htcore.mark_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_momentum(optimizer, to_filters_last, lazy_mode):\n",
    "    # Permute the momentum buffer before using for checkpoint\n",
    "    for group in optimizer.param_groups:\n",
    "        for p in group[\"params\"]:\n",
    "            param_state = optimizer.state[p]\n",
    "            if \"momentum_buffer\" in param_state:\n",
    "                buf = param_state[\"momentum_buffer\"]\n",
    "                if buf.ndim == 4:\n",
    "                    if to_filters_last:\n",
    "                        buf = buf.permute((2, 3, 1, 0))\n",
    "                    else:\n",
    "                        buf = buf.permute((3, 2, 0, 1))\n",
    "                    param_state[\"momentum_buffer\"] = buf\n",
    "\n",
    "    if lazy_mode:\n",
    "        import habana_frameworks.torch.core as htcore\n",
    "\n",
    "        htcore.mark_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68140438",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f243f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_params(model, True, True)\n",
    "permute_momentum(optimizer, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaef10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename):\n",
    "    torch.save(state[\"state_dict\"], filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, \"model_best\" + str(state[\"epoch\"]) + \".pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a114ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, epoch):\n",
    "    for i, (images, target) in enumerate(pbar := tqdm(train_loader)):\n",
    "        pbar.set_description(f\"Training\")\n",
    "        images, target = images.to(device, non_blocking=True), target.to(\n",
    "            device, non_blocking=True\n",
    "        ).unsqueeze(1)\n",
    "        images = images.contiguous(memory_format=torch.channels_last)\n",
    "        htcore.mark_step()\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        htcore.mark_step()\n",
    "        optimizer.step()\n",
    "        htcore.mark_step()\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                \"Train Epoch\": epoch,\n",
    "                \"Train Loss\": loss.item(),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, device):\n",
    "    dice_score = 0\n",
    "    with torch.no_grad():\n",
    "        data_end = time.time()\n",
    "        for i, (images, target) in enumerate(pbar := tqdm(val_loader)):\n",
    "            pbar.set_description(f\"Validating\")\n",
    "            images, target = images.to(device, non_blocking=True), target.to(\n",
    "                device, non_blocking=True\n",
    "            ).unsqueeze(1)\n",
    "            images = images.contiguous(memory_format=torch.channels_last)\n",
    "            htcore.mark_step()\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = (torch.sigmoid(output) > 0.5).float()\n",
    "            dice_score += (2 * (preds * target).sum()) / ((preds + target).sum() + 1e-7)\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    \"Validation Epoch\": epoch,\n",
    "                    \"Validation Loss\": loss.item(),\n",
    "                    \"Dice Score\": (dice_score / i).item(),\n",
    "                }\n",
    "            )\n",
    "    return dice_score / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba54815",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "e_time = start_time\n",
    "best_acc1 = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    train(train_loader, epoch)\n",
    "    # evaluate on validation set\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    model_for_eval = model\n",
    "    acc1 = validate(val_loader, model_for_eval, criterion, device)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    if is_best:\n",
    "        print(\n",
    "            f\"Dice score inreased from {best_acc1} --> {acc1} --> Saving checkpoint epoch {epoch} \"\n",
    "        )\n",
    "        # Permute model parameters from RSCK to KCRS\n",
    "        model_without_ddp = model\n",
    "        permute_params(model_without_ddp, False, True)\n",
    "        # Use this model only to copy the state_dict of the actual model\n",
    "        copy_model = UNET(in_channels=3, out_channels=1)\n",
    "        state_dict = model_without_ddp.state_dict()\n",
    "        for k, v in state_dict.items():\n",
    "            if \"num_batches_tracked\" in k and v.dim() == 1:\n",
    "                state_dict[k] = v.squeeze(0)\n",
    "\n",
    "        copy_model.load_state_dict(state_dict)\n",
    "        # Permute the weight momentum buffer before saving in checkpoint\n",
    "        permute_momentum(optimizer, False, True)\n",
    "\n",
    "        # Bring all model parameters and optimizer parameters to CPU\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(\"cpu\")\n",
    "\n",
    "        # Save model parameters in checkpoint\n",
    "        dir_ = \"checkpoints/\"\n",
    "        filename = dir_ + \"checkpoint_\" + str(epoch) + \"_\" + \"hpu\" + \".pth\"\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"arch\": model,\n",
    "                \"state_dict\": copy_model.state_dict(),\n",
    "                \"best_acc1\": best_acc1,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            },\n",
    "            is_best,\n",
    "            filename,\n",
    "        )\n",
    "\n",
    "        # Take back model parameters and optimizer parameters to HPU\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(\"hpu\")\n",
    "        # Permute back from KCRS to RSCK\n",
    "        permute_params(model, True, True)\n",
    "        permute_momentum(optimizer, True, True)\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print(\"Training time {}\".format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state[\"state_dict\"], \"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3559195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
